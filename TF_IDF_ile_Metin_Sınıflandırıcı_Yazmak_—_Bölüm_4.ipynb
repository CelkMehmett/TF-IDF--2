{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "BVEdKcZ4w7Dt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.model_selection import train_test_split, cross_val_score\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import joblib\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n"
      ],
      "metadata": {
        "id": "in6CNMIsw7iS"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = [\n",
        "    # kişisel gelişim\n",
        "    (\"Her sabah erken kalkmaya çalışıyorum\", \"kişisel gelişim\"),\n",
        "    (\"Hedeflerime ulaşmak için plan yapıyorum\", \"kişisel gelişim\"),\n",
        "    (\"Zaman yönetimi konusunda daha dikkatli olmalıyım\", \"kişisel gelişim\"),\n",
        "    (\"Yeni bir dil öğrenmeye başladım\", \"kişisel gelişim\"),\n",
        "    (\"Motivasyonumu yüksek tutmak istiyorum\", \"kişisel gelişim\"),\n",
        "    (\"Kitap okumayı günlük rutin haline getirdim\", \"kişisel gelişim\"),\n",
        "    (\"Online kurslara katılıp kendimi geliştiriyorum\", \"kişisel gelişim\"),\n",
        "    (\"Stresi yönetmek için meditasyon yapıyorum\", \"kişisel gelişim\"),\n",
        "    (\"Kariyerimde ilerlemek için sertifika alıyorum\", \"kişisel gelişim\"),\n",
        "    (\"Verimli çalışmak için pomodoro tekniğini deniyorum\", \"kişisel gelişim\"),\n",
        "\n",
        "    # günlük yaşam\n",
        "    (\"Bugün kahvaltıda menemen yaptım\", \"günlük yaşam\"),\n",
        "    (\"Akşam yürüyüşüne çıkacağım\", \"günlük yaşam\"),\n",
        "    (\"Çamaşırları yıkayıp astım\", \"günlük yaşam\"),\n",
        "    (\"Marketten süt ve ekmek aldım\", \"günlük yaşam\"),\n",
        "    (\"Hava çok güzel, dışarı çıkmak istiyorum\", \"günlük yaşam\"),\n",
        "    (\"Arkadaşlarımla sinemaya gittik\", \"günlük yaşam\"),\n",
        "    (\"Bugün hiç canım bir şey yapmak istemiyor\", \"günlük yaşam\"),\n",
        "    (\"Telefonumun şarjı hemen bitiyor\", \"günlük yaşam\"),\n",
        "    (\"Ev temizliği yaptım, çok yoruldum\", \"günlük yaşam\"),\n",
        "    (\"Dizimin ağrısı geçmedi, doktora gitmeliyim\", \"günlük yaşam\"),\n",
        "\n",
        "    # talep/şikayet\n",
        "    (\"Mahallemizde çöpler toplanmıyor\", \"talep/şikayet\"),\n",
        "    (\"Sokak lambaları gece yanmıyor\", \"talep/şikayet\"),\n",
        "    (\"İnternet bağlantım sürekli kopuyor\", \"talep/şikayet\"),\n",
        "    (\"Kargom hala teslim edilmedi\", \"talep/şikayet\"),\n",
        "    (\"Site giriş kapısı bozuk, kimse ilgilenmiyor\", \"talep/şikayet\"),\n",
        "    (\"Toplu taşıma saatleri yetersiz\", \"talep/şikayet\"),\n",
        "    (\"Elektrik kesintisi çok uzun sürdü\", \"talep/şikayet\"),\n",
        "    (\"Whatsapp destek hattına ulaşamıyorum\", \"talep/şikayet\"),\n",
        "    (\"Uygulama sürekli çöküyor, acil çözüm gerekiyor\", \"talep/şikayet\"),\n",
        "    (\"Faturam yüksek geldi, itiraz etmek istiyorum\", \"talep/şikayet\"),\n",
        "]\n",
        "df = pd.DataFrame(data, columns=[\"text\", \"label\"])\n",
        "le = LabelEncoder()\n",
        "y = le.fit_transform(df[\"label\"])"
      ],
      "metadata": {
        "id": "VJbul62jw_Bm"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "turkish_stopwords = [\n",
        "    'acaba', 'ama', 'aslında', 'az', 'bazı', 'belki', 'biri', 'birkaç', 'birşey', 'biz',\n",
        "    'bu', 'çok', 'çünkü', 'da', 'daha', 'de', 'defa', 'diye', 'en', 'gibi', 'hem', 'hep', 'hepsi',\n",
        "    'her', 'hiç', 'için', 'ile', 'ise', 'kez', 'ki', 'kim', 'mı', 'mu', 'mü', 'nasıl', 'ne',\n",
        "    'neden', 'nerde', 'nerede', 'nereye', 'niçin', 'niye', 'o', 'sanki', 'şey', 'siz',\n",
        "    'şu', 'tüm', 've', 'veya', 'ya', 'yani', 'ben', 'sen', 'o', 'biz', 'siz', 'onlar',\n",
        "    'şimdi', 'zaten', 'artık', 'üzerine', 'olarak', 'ile', 'et', 'var', 'yok', 'mıydı', 'değil',\n",
        "    'bile', 'herhangi', 'hangi', 'herkes', 'bazıları', 'bazılarıyla', 'ise', 'ya da',\n",
        "    'içinde', 'üzerinde', 'altında', 'arasında', 'üstünde', 'sonra', 'önce', 'bir', 'birini',\n",
        "    'birine', 'birisi', 'birisiyle', 'birlikte', 'bir şey', 'her şey', 'hiçbir şey',\n",
        "    'hiç kimse', 'herkes', 'şimdi', 'önce', 'sonra', 'zaten', 'aslında', 'elbette'\n",
        "]\n"
      ],
      "metadata": {
        "id": "6dNrI8uF5c27"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words=turkish_stopwords,\n",
        "    ngram_range=(1, 2),\n",
        "    max_df=0.9,\n",
        "    min_df=1\n",
        ")\n",
        "X = vectorizer.fit_transform(df[\"text\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nelXnzaLx5uD",
        "outputId": "b11e7579-91e0-4de1-b582-b6040823843a"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['hiçbir', 'kimse'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(\n",
        "    stop_words=turkish_stopwords,\n",
        "    ngram_range=(1, 2)  # Unigram + Bigram\n",
        ")\n",
        "X = vectorizer.fit_transform(df[\"text\"])\n"
      ],
      "metadata": {
        "id": "I8QXDKIY4OmH"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words=turkish_stopwords, ngram_range=(1, 2))),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "pipeline.fit(df[\"text\"], y)\n",
        "\n",
        "# Test cümlesi\n",
        "test = [\"Bugün yeni kararlar aldım ve kendimi geliştirmek istiyorum\"]\n",
        "pred = pipeline.predict(test)\n",
        "print(\"Tahmin:\", le.inverse_transform(pred)[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fE_n9GG95xRz",
        "outputId": "8066a43b-6043-4b41-a556-3f93273b08ae"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tahmin: günlük yaşam\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_extraction/text.py:402: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['hiçbir', 'kimse'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "models = {\n",
        "    \"Naive Bayes\": MultinomialNB(),\n",
        "    \"Lojistik Regresyon\": LogisticRegression(max_iter=200),\n",
        "    \"Karar Ağacı\": DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "for name, clf in models.items():\n",
        "    pipe = Pipeline([\n",
        "        ('tfidf', TfidfVectorizer(stop_words=turkish_stopwords, ngram_range=(1, 2))),\n",
        "        ('clf', clf)\n",
        "    ])\n",
        "    scores = cross_val_score(pipe, df[\"text\"], y, cv=5)\n",
        "    print(f\"{name}: Ortalama doğruluk: {scores.mean():.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Av8OcfD61yk",
        "outputId": "0f3f5ff9-bd6b-43e0-96fb-0ca2be02b26e"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Naive Bayes: Ortalama doğruluk: 0.43\n",
            "Lojistik Regresyon: Ortalama doğruluk: 0.40\n",
            "Karar Ağacı: Ortalama doğruluk: 0.33\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Pipeline tanımı\n",
        "pipeline = Pipeline([\n",
        "    ('tfidf', TfidfVectorizer(stop_words=turkish_stopwords)),\n",
        "    ('clf', MultinomialNB())\n",
        "])\n",
        "\n",
        "# Parametre aralığı\n",
        "param_grid = {\n",
        "    'tfidf__ngram_range': [(1,1), (1,2)],\n",
        "    'tfidf__max_df': [0.75, 0.9, 1.0],\n",
        "    'tfidf__min_df': [1, 2],\n",
        "    'clf__alpha': [0.1, 1.0, 10.0]\n",
        "}\n",
        "\n",
        "# GridSearch başlat\n",
        "grid_search = GridSearchCV(\n",
        "    pipeline,\n",
        "    param_grid,\n",
        "    cv=5,\n",
        "    scoring='accuracy',\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "grid_search.fit(df[\"text\"], y)\n",
        "print(\"En iyi doğruluk:\", grid_search.best_score_)\n",
        "print(\"En iyi parametreler:\", grid_search.best_params_)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilHppk_u8o0L",
        "outputId": "a39edeee-e8f6-4136-d2fe-0d2f244a77c3"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "En iyi doğruluk: 0.4333333333333334\n",
            "En iyi parametreler: {'clf__alpha': 0.1, 'tfidf__max_df': 0.75, 'tfidf__min_df': 1, 'tfidf__ngram_range': (1, 1)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "best_model = grid_search.best_estimator_\n",
        "\n",
        "# Modeli ve LabelEncoder’ı kaydet\n",
        "joblib.dump(best_model, \"tfidf_tr_model.pkl\")\n",
        "joblib.dump(le, \"label_encoder.pkl\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_HgKQCFs9GjS",
        "outputId": "4266da3f-b0a5-49f5-f78c-f78828ac3a2d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['label_encoder.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model ve etiket çözücü yeniden yüklenebilir\n",
        "model = joblib.load(\"tfidf_tr_model.pkl\")\n",
        "label_encoder = joblib.load(\"label_encoder.pkl\")\n",
        "\n",
        "# Örnek tahmin\n",
        "text = [\"Bugün motivasyonum düştü ama tekrar plan yapacağım\"]\n",
        "pred = model.predict([text[0]])\n",
        "print(\"Tahmin:\", label_encoder.inverse_transform(pred)[0])\n"
      ],
      "metadata": {
        "id": "aNakAoNv9lJp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}